{"cells": [{"cell_type": "code", "execution_count": 1, "metadata": {"tags": []}, "outputs": [], "source": "from pyspark.sql import SparkSession\n# import pyspark.sql.functions as F\nfrom pyspark.sql.functions import col, isnan, when, count, udf, to_date, year, month, date_format, size, split, datediff, regexp_extract, lit, abs\nfrom pyspark.ml.stat import Correlation\nfrom pyspark.ml.feature import VectorAssembler, OneHotEncoder, MinMaxScaler, StringIndexer\nfrom pyspark.ml import Pipeline\nfrom pyspark.ml.regression import LinearRegression\nfrom pyspark.ml.evaluation import BinaryClassificationEvaluator, RegressionEvaluator\nfrom pyspark.ml.tuning import CrossValidator, ParamGridBuilder"}, {"cell_type": "code", "execution_count": 2, "metadata": {"tags": []}, "outputs": [{"data": {"text/html": "\n            <div>\n                <p><b>SparkSession - hive</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://cluster-5f6a-m.us-central1-f.c.semester-project-fall-2024.internal:34315\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.5.1</code></dd>\n              <dt>Master</dt>\n                <dd><code>yarn</code></dd>\n              <dt>AppName</dt>\n                <dd><code>PySparkShell</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        ", "text/plain": "<pyspark.sql.session.SparkSession at 0x7f2b8d03cc90>"}, "execution_count": 2, "metadata": {}, "output_type": "execute_result"}], "source": "spark"}, {"cell_type": "code", "execution_count": 3, "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "cleaned_data_path = 'gs://my-bigdata-project-rn/cleaned/cleaned_itineraries.parquet'\n#Sample used to collect only 5% of random data. Will be adjusted\nsdf = spark.read.parquet(cleaned_data_path, header=True, inferSchema=True)"}, {"cell_type": "code", "execution_count": 4, "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- searchDate: date (nullable = true)\n |-- flightDate: date (nullable = true)\n |-- startingAirport: string (nullable = true)\n |-- destinationAirport: string (nullable = true)\n |-- travelDuration: string (nullable = true)\n |-- elapsedDays: integer (nullable = true)\n |-- isBasicEconomy: boolean (nullable = true)\n |-- isNonStop: boolean (nullable = true)\n |-- totalFare: double (nullable = true)\n |-- seatsRemaining: integer (nullable = true)\n |-- totalTravelDistance: integer (nullable = true)\n |-- segmentsArrivalAirportCode: string (nullable = true)\n |-- segmentsDepartureAirportCode: string (nullable = true)\n |-- segmentsAirlineCode: string (nullable = true)\n |-- segmentsEquipmentDescription: string (nullable = true)\n |-- segmentsDurationInSeconds: string (nullable = true)\n |-- segmentsDistance: string (nullable = true)\n |-- segmentsCabinCode: string (nullable = true)\n\n"}], "source": "#Ensure search and flight date are datetime values\nsdf.printSchema()"}, {"cell_type": "code", "execution_count": 5, "metadata": {"tags": []}, "outputs": [], "source": "#Remove totalFare values over $5500. Considered outliers\nsdf = sdf.filter(col('totalFare') < 5500)"}, {"cell_type": "code", "execution_count": 6, "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "24/12/13 00:55:11 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "+-------+---------------+------------------+--------------+-------------------+------------------+------------------+-------------------+--------------------------+----------------------------+-------------------+----------------------------+-------------------------+------------------+--------------------+\n|summary|startingAirport|destinationAirport|travelDuration|        elapsedDays|         totalFare|    seatsRemaining|totalTravelDistance|segmentsArrivalAirportCode|segmentsDepartureAirportCode|segmentsAirlineCode|segmentsEquipmentDescription|segmentsDurationInSeconds|  segmentsDistance|   segmentsCabinCode|\n+-------+---------------+------------------+--------------+-------------------+------------------+------------------+-------------------+--------------------------+----------------------------+-------------------+----------------------------+-------------------------+------------------+--------------------+\n|  count|       74754181|          74754181|      74754181|           74754181|          74754181|          74754181|           74754181|                  74754181|                    74754181|           74754181|                    74754181|                 74754181|          74754181|            74754181|\n|   mean|           NULL|              NULL|          NULL|0.14639516952235757|350.59882868371795| 6.398238849008325| 1612.2629549643518|                      NULL|                        NULL|               NULL|                        NULL|        10664.85070120878|1054.5632295505993|                NULL|\n| stddev|           NULL|              NULL|          NULL| 0.3535042539352249| 197.1190969506286|2.4954599436632807|   857.616664680521|                      NULL|                        NULL|               NULL|                        NULL|         5005.27999918394| 708.0146718415891|                NULL|\n|    min|            ATL|               ATL|           P1D|                  0|             22.47|                 0|                 89|                  ABE||ATL|                         ATL|         4B||4B||AA|        AIRBUS INDUSTRIE ...|                    10020|        1003||1110|            business|\n|    25%|           NULL|              NULL|          NULL|                  0|             203.6|                 5|                891|                      NULL|                        NULL|               NULL|                        NULL|                   7020.0|             545.0|                NULL|\n|    50%|           NULL|              NULL|          NULL|                  0|             316.1|                 7|               1468|                      NULL|                        NULL|               NULL|                        NULL|                   9240.0|             799.0|                NULL|\n|    75%|           NULL|              NULL|          NULL|                  0|             464.6|                 9|               2417|                      NULL|                        NULL|               NULL|                        NULL|                  13200.0|            1380.0|                NULL|\n|    max|            SFO|               SFO|        PT9H9M|                  2|            5096.6|                10|               7252|             XNA||ORD||DTW|                    TTN||RSW|     UA||UA||UA||UA|         ||||Embraer EMB-145|         9960||9960||8160|       99||59||672|premium coach||pr...|\n+-------+---------------+------------------+--------------+-------------------+------------------+------------------+-------------------+--------------------------+----------------------------+-------------------+----------------------------+-------------------------+------------------+--------------------+\n\n"}], "source": "sdf.summary().show()"}, {"cell_type": "code", "execution_count": 7, "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+----------+--------------------+--------------------+\n|flightDate|flightDate_DayOfWeek|flightDate_OnWeekend|\n+----------+--------------------+--------------------+\n|2022-07-01|              Friday|                   0|\n|2022-07-01|              Friday|                   0|\n|2022-07-01|              Friday|                   0|\n|2022-07-01|              Friday|                   0|\n|2022-07-01|              Friday|                   0|\n|2022-07-01|              Friday|                   0|\n|2022-07-01|              Friday|                   0|\n|2022-07-01|              Friday|                   0|\n|2022-07-01|              Friday|                   0|\n|2022-07-01|              Friday|                   0|\n+----------+--------------------+--------------------+\nonly showing top 10 rows\n\n"}], "source": "# Engineer additional date feature columns based on the order_date\n# Goal is to have a flightDate_OnWeekend column\nsdf = sdf.withColumn(\"flightDate_DayOfWeek\", date_format(col(\"flightDate\"), \"EEEE\"))         # 'Monday' 'Tuesday' etc.\nsdf = sdf.withColumn(\"flightDate_OnWeekend\", when(sdf.flightDate_DayOfWeek == 'Saturday',1.0).when(sdf.flightDate_DayOfWeek == 'Sunday', 1.0).otherwise(0).cast('int'))\n\n# Check columns to see if we got good values\nsdf.select(['flightDate','flightDate_DayOfWeek', 'flightDate_OnWeekend']).show(10)"}, {"cell_type": "code", "execution_count": 8, "metadata": {"tags": []}, "outputs": [], "source": "#Create daysBetweenFlight column\nsdf = sdf.withColumn(\"daysBetweenFlight\", datediff(sdf.flightDate, sdf.searchDate))"}, {"cell_type": "code", "execution_count": 9, "metadata": {"tags": []}, "outputs": [], "source": "#Create total travel duration column in a proper format\nsdf = sdf.withColumn(\"travelduration_hours\", regexp_extract(col(\"travelDuration\"), r\"(\\d+)H\",1).cast(\"int\"))\nsdf = sdf.withColumn(\"travelduration_minutes\", regexp_extract(col(\"travelDuration\"), r\"(\\d+)M\",1).cast(\"int\"))\nsdf = sdf.na.fill(value=0.0,subset=[\"travelduration_minutes\", \"travelduration_hours\"])\nsdf = sdf.withColumn(\"travelduration_total_minutes\", col(\"travelduration_hours\") * 60 + col(\"travelduration_minutes\"))"}, {"cell_type": "code", "execution_count": 10, "metadata": {"tags": []}, "outputs": [], "source": "#Mapping true/false columns to 1 and 0\nsdf = sdf.withColumn('isBasicEconomy', when(sdf.isBasicEconomy == 'true', 1).otherwise(0))\nsdf = sdf.withColumn('isNonStop', when(sdf.isNonStop == 'true', 1).otherwise(0))"}, {"cell_type": "code", "execution_count": 11, "metadata": {"tags": []}, "outputs": [], "source": "#Remove outlier elapsedDays values greater than 1\nsdf = sdf.filter(col('elapsedDays') < 2)"}, {"cell_type": "code", "execution_count": 12, "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "[Stage 7:>                                                          (0 + 1) / 1]\r"}, {"name": "stdout", "output_type": "stream", "text": "+-----------+--------+\n|elapsedDays|   count|\n+-----------+--------+\n|          1|10943529|\n|          0|63810591|\n+-----------+--------+\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "#Verify no more outliers exist\nsdf.groupBy('elapsedDays').count().show()"}, {"cell_type": "code", "execution_count": 14, "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "ERROR:root:KeyboardInterrupt while sending command.               (0 + 18) / 18]\nTraceback (most recent call last):\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py\", line 1038, in send_command\n    response = connection.send_command(command)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/lib/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py\", line 511, in send_command\n    answer = smart_decode(self.stream.readline()[:-1])\n                          ^^^^^^^^^^^^^^^^^^^^^^\n  File \"/opt/conda/miniconda3/lib/python3.11/socket.py\", line 706, in readinto\n    return self._sock.recv_into(b)\n           ^^^^^^^^^^^^^^^^^^^^^^^\nKeyboardInterrupt\n"}, {"ename": "KeyboardInterrupt", "evalue": "", "output_type": "error", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)", "Cell \u001b[0;32mIn[14], line 29\u001b[0m\n\u001b[1;32m     26\u001b[0m regression_pipe \u001b[38;5;241m=\u001b[39m Pipeline(stages\u001b[38;5;241m=\u001b[39m[indexer, encoder, distance_assembler, totalDistance_scaler, assembler, ridge_reg])\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Call .fit to transform the data\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m transformed_sdf \u001b[38;5;241m=\u001b[39m \u001b[43mregression_pipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43msdf\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(sdf)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Review the transformed features\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTransformed features\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n", "File \u001b[0;32m/usr/lib/spark/python/pyspark/ml/base.py:205\u001b[0m, in \u001b[0;36mEstimator.fit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(params)\u001b[38;5;241m.\u001b[39m_fit(dataset)\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParams must be either a param map or a list/tuple of param maps, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    209\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(params)\n\u001b[1;32m    210\u001b[0m     )\n", "File \u001b[0;32m/usr/lib/spark/python/pyspark/ml/pipeline.py:134\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    132\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m stage\u001b[38;5;241m.\u001b[39mtransform(dataset)\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# must be an Estimator\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mstage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m     transformers\u001b[38;5;241m.\u001b[39mappend(model)\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m<\u001b[39m indexOfLastEstimator:\n", "File \u001b[0;32m/usr/lib/spark/python/pyspark/ml/base.py:205\u001b[0m, in \u001b[0;36mEstimator.fit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy(params)\u001b[38;5;241m.\u001b[39m_fit(dataset)\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParams must be either a param map or a list/tuple of param maps, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    209\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mtype\u001b[39m(params)\n\u001b[1;32m    210\u001b[0m     )\n", "File \u001b[0;32m/usr/lib/spark/python/pyspark/ml/wrapper.py:381\u001b[0m, in \u001b[0;36mJavaEstimator._fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_fit\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset: DataFrame) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m JM:\n\u001b[0;32m--> 381\u001b[0m     java_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_java\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    382\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_model(java_model)\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_copyValues(model)\n", "File \u001b[0;32m/usr/lib/spark/python/pyspark/ml/wrapper.py:378\u001b[0m, in \u001b[0;36mJavaEstimator._fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_java_obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transfer_params_to_java()\n\u001b[0;32m--> 378\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_java_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[43m)\u001b[49m\n", "File \u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1314\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n", "File \u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_connection()\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1038\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m binary:\n\u001b[1;32m   1040\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection_guard(connection)\n", "File \u001b[0;32m/usr/lib/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:511\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m         answer \u001b[38;5;241m=\u001b[39m smart_decode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream\u001b[38;5;241m.\u001b[39mreadline()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    512\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer received: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(answer))\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;66;03m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;66;03m# answer before the socket raises an error.\u001b[39;00m\n", "File \u001b[0;32m/opt/conda/miniconda3/lib/python3.11/socket.py:706\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    704\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 706\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    707\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    708\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n", "\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}, {"name": "stderr", "output_type": "stream", "text": "[Stage 93:======>                                                 (2 + 16) / 18]\r"}], "source": "#Apply MinMax to TotalTravelDistance\nsdf = sdf.withColumn('totalTravelDistance', sdf.totalTravelDistance.cast('double'))\ndistance_assembler = VectorAssembler(inputCols=['totalTravelDistance'], outputCol='distanceVector')\ntotalDistance_scaler = MinMaxScaler(inputCol = 'distanceVector', outputCol = 'totalDistanceScaled')\n\n#Indexer for string columns\nindexer = StringIndexer(inputCols=['startingAirport', 'destinationAirport', 'segmentsArrivalAirportCode', 'segmentsCabinCode'], \n                        outputCols=['startAirportIndex', 'destAirportIndex', 'arrivalAirportCodeIndex', 'cabinCodeIndex'], handleInvalid=\"keep\")\n\n#One-Hot encoder\nencoder = OneHotEncoder(inputCols=['startAirportIndex', 'destAirportIndex', 'arrivalAirportCodeIndex', 'cabinCodeIndex'],\n                        outputCols=['startAirportVector', 'destAirportVector', 'arrivalAirportCodeVector', 'cabinCodeVector'],\n                        dropLast=False)\n\n#Creating the assembler for the feature vectors and integer columns used\nassembler = VectorAssembler(inputCols=['startAirportVector', 'destAirportVector', 'arrivalAirportCodeVector', 'cabinCodeVector','daysBetweenFlight', 'flightDate_OnWeekend','travelduration_total_minutes', 'elapsedDays', 'isBasicEconomy', 'isNonStop', 'seatsRemaining', 'totalDistanceScaled'], outputCol='features')\n\n# Create a Ridge Regression Estimator\nridge_reg = LinearRegression(labelCol='totalFare',  elasticNetParam=0, regParam=0.1)\n\n# Create a regression evaluator (to get RMSE, R2, RME, etc.)\nevaluator = RegressionEvaluator(labelCol='totalFare')\n\n#Creating the pipeline\n\nregression_pipe = Pipeline(stages=[indexer, encoder, distance_assembler, totalDistance_scaler, assembler, ridge_reg])\n\n# Call .fit to transform the data\ntransformed_sdf = regression_pipe.fit(sdf).transform(sdf)\n\n# Review the transformed features\nprint(\"Transformed features\")\ntransformed_sdf.select('daysBetweenFlight', 'flightDate_OnWeekend','startingAirport','destinationAirport', 'travelduration_total_minutes', 'elapsedDays', 'isBasicEconomy', 'isNonStop', 'seatsRemaining', 'totalTravelDistance', 'segmentsArrivalAirportCode', 'segmentsCabinCode', 'totalFare', 'features').show(30, truncate=False)"}, {"cell_type": "code", "execution_count": 15, "metadata": {"tags": []}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Number of models to be tested:  50\n"}, {"name": "stderr", "output_type": "stream", "text": "24/12/13 01:14:06 WARN DAGScheduler: Broadcasting large task binary with size 1749.7 KiB\n24/12/13 01:14:32 WARN DAGScheduler: Broadcasting large task binary with size 1750.9 KiB\n24/12/13 01:14:32 WARN DAGScheduler: Broadcasting large task binary with size 1750.2 KiB\n24/12/13 01:14:59 WARN DAGScheduler: Broadcasting large task binary with size 1751.4 KiB\n24/12/13 01:14:59 WARN DAGScheduler: Broadcasting large task binary with size 1750.2 KiB\n24/12/13 01:14:59 WARN DAGScheduler: Broadcasting large task binary with size 1751.4 KiB\n24/12/13 01:14:59 WARN DAGScheduler: Broadcasting large task binary with size 1750.2 KiB\n24/12/13 01:15:00 WARN DAGScheduler: Broadcasting large task binary with size 1751.4 KiB\n24/12/13 01:15:00 WARN DAGScheduler: Broadcasting large task binary with size 1750.2 KiB\n24/12/13 01:15:00 WARN DAGScheduler: Broadcasting large task binary with size 1751.4 KiB\n24/12/13 01:15:00 WARN DAGScheduler: Broadcasting large task binary with size 1750.2 KiB\n24/12/13 01:15:01 WARN DAGScheduler: Broadcasting large task binary with size 1751.4 KiB\n24/12/13 01:15:01 WARN DAGScheduler: Broadcasting large task binary with size 1750.2 KiB\n24/12/13 01:15:01 WARN DAGScheduler: Broadcasting large task binary with size 1751.4 KiB\n24/12/13 01:15:01 WARN DAGScheduler: Broadcasting large task binary with size 1750.2 KiB\n24/12/13 01:15:02 WARN DAGScheduler: Broadcasting large task binary with size 1751.4 KiB\n24/12/13 01:15:02 WARN DAGScheduler: Broadcasting large task binary with size 1750.2 KiB\n24/12/13 01:15:02 WARN DAGScheduler: Broadcasting large task binary with size 1751.4 KiB\n24/12/13 01:15:02 WARN DAGScheduler: Broadcasting large task binary with size 1750.2 KiB\n24/12/13 01:15:03 WARN DAGScheduler: Broadcasting large task binary with size 1751.4 KiB\n24/12/13 01:15:03 WARN DAGScheduler: Broadcasting large task binary with size 1750.2 KiB\n24/12/13 01:15:03 WARN DAGScheduler: Broadcasting large task binary with size 1751.4 KiB\n24/12/13 01:15:03 WARN DAGScheduler: Broadcasting large task binary with size 1750.2 KiB\n24/12/13 01:15:04 WARN DAGScheduler: Broadcasting large task binary with size 1751.4 KiB\n24/12/13 01:15:04 WARN DAGScheduler: Broadcasting large task binary with size 1750.2 KiB\n24/12/13 01:15:04 WARN DAGScheduler: Broadcasting large task binary with size 1751.4 KiB\n24/12/13 01:15:04 WARN DAGScheduler: Broadcasting large task binary with size 1750.2 KiB\n24/12/13 01:15:05 WARN DAGScheduler: Broadcasting large task binary with size 1751.4 KiB\n24/12/13 01:15:05 WARN DAGScheduler: Broadcasting large task binary with size 1750.2 KiB\n24/12/13 01:15:05 WARN DAGScheduler: Broadcasting large task binary with size 1751.4 KiB\n24/12/13 01:15:05 WARN DAGScheduler: Broadcasting large task binary with size 1750.2 KiB\n24/12/13 01:15:06 WARN DAGScheduler: Broadcasting large task binary with size 1751.4 KiB\n24/12/13 01:15:06 WARN DAGScheduler: Broadcasting large task binary with size 1750.2 KiB\n24/12/13 01:15:06 WARN DAGScheduler: Broadcasting large task binary with size 1751.4 KiB\n24/12/13 01:15:06 WARN DAGScheduler: Broadcasting large task binary with size 1750.2 KiB\n24/12/13 01:15:07 WARN DAGScheduler: Broadcasting large task binary with size 1751.4 KiB\n24/12/13 01:15:07 WARN DAGScheduler: Broadcasting large task binary with size 1750.2 KiB\n24/12/13 01:15:07 WARN DAGScheduler: Broadcasting large task binary with size 1751.4 KiB\n24/12/13 01:15:07 WARN DAGScheduler: Broadcasting large task binary with size 1750.2 KiB\n24/12/13 01:15:08 WARN DAGScheduler: Broadcasting large task binary with size 1751.4 KiB\n24/12/13 01:15:08 WARN DAGScheduler: Broadcasting large task binary with size 1750.2 KiB\n24/12/13 01:15:08 WARN DAGScheduler: Broadcasting large task binary with size 1751.4 KiB\n24/12/13 01:15:08 WARN DAGScheduler: Broadcasting large task binary with size 1750.2 KiB\n24/12/13 01:15:09 WARN DAGScheduler: Broadcasting large task binary with size 1751.4 KiB\n24/12/13 01:15:09 WARN DAGScheduler: Broadcasting large task binary with size 1750.2 KiB\n24/12/13 01:15:09 WARN DAGScheduler: Broadcasting large task binary with size 1751.4 KiB\n24/12/13 01:15:09 WARN DAGScheduler: Broadcasting large task binary with size 1750.2 KiB\n24/12/13 01:15:10 WARN DAGScheduler: Broadcasting large task binary with size 1751.4 KiB\n24/12/13 01:15:10 WARN DAGScheduler: Broadcasting large task binary with size 1750.2 KiB\n24/12/13 01:15:10 WARN DAGScheduler: Broadcasting large task binary with size 1751.4 KiB\n24/12/13 01:15:10 WARN DAGScheduler: Broadcasting large task binary with size 1750.2 KiB\n24/12/13 01:15:11 WARN DAGScheduler: Broadcasting large task binary with size 1751.4 KiB\n24/12/13 01:15:11 WARN DAGScheduler: Broadcasting large task binary with size 1750.2 KiB\n24/12/13 01:15:11 WARN DAGScheduler: Broadcasting large task binary with size 1751.4 KiB\n24/12/13 01:15:11 WARN DAGScheduler: Broadcasting large task binary with size 1750.2 KiB\n24/12/13 01:15:12 WARN DAGScheduler: Broadcasting large task binary with size 1751.4 KiB\n24/12/13 01:15:12 WARN DAGScheduler: Broadcasting large task binary with size 1750.2 KiB\n24/12/13 01:15:12 WARN DAGScheduler: Broadcasting large task binary with size 1751.4 KiB\n24/12/13 01:15:12 WARN DAGScheduler: Broadcasting large task binary with size 1750.2 KiB\n24/12/13 01:15:13 WARN DAGScheduler: Broadcasting large task binary with size 1751.4 KiB\n24/12/13 01:15:13 WARN DAGScheduler: Broadcasting large task binary with size 1750.2 KiB\n24/12/13 01:15:13 WARN DAGScheduler: Broadcasting large task binary with size 1751.4 KiB\n24/12/13 01:15:13 WARN DAGScheduler: Broadcasting large task binary with size 1750.2 KiB\n24/12/13 01:15:14 WARN DAGScheduler: Broadcasting large task binary with size 1751.4 KiB\n24/12/13 01:15:14 WARN DAGScheduler: Broadcasting large task binary with size 1750.2 KiB\n24/12/13 01:15:14 WARN DAGScheduler: Broadcasting large task binary with size 1751.4 KiB\n24/12/13 01:15:14 WARN DAGScheduler: Broadcasting large task binary with size 1750.2 KiB\n24/12/13 01:15:15 WARN DAGScheduler: Broadcasting large task binary with size 1751.4 KiB\n24/12/13 01:15:15 WARN DAGScheduler: Broadcasting large task binary with size 1750.2 KiB\n24/12/13 01:15:15 WARN DAGScheduler: Broadcasting large task binary with size 1751.4 KiB\n24/12/13 01:15:15 WARN DAGScheduler: Broadcasting large task binary with size 1750.2 KiB\n24/12/13 01:15:16 WARN DAGScheduler: Broadcasting large task binary with size 1751.4 KiB\n24/12/13 01:15:16 WARN DAGScheduler: Broadcasting large task binary with size 1750.2 KiB\n24/12/13 01:15:16 WARN DAGScheduler: Broadcasting large task binary with size 1751.4 KiB\n24/12/13 01:15:16 WARN DAGScheduler: Broadcasting large task binary with size 1750.2 KiB\n24/12/13 01:15:16 WARN DAGScheduler: Broadcasting large task binary with size 1751.4 KiB\n24/12/13 01:15:17 WARN DAGScheduler: Broadcasting large task binary with size 1813.3 KiB\n24/12/13 01:15:40 WARN DAGScheduler: Broadcasting large task binary with size 1814.4 KiB\n24/12/13 01:16:29 WARN DAGScheduler: Broadcasting large task binary with size 1813.8 KiB\n24/12/13 01:16:42 WARN DAGScheduler: Broadcasting large task binary with size 1814.9 KiB\n24/12/13 01:17:51 WARN DAGScheduler: Broadcasting large task binary with size 1754.7 KiB\n24/12/13 01:18:16 WARN DAGScheduler: Broadcasting large task binary with size 1755.9 KiB\n24/12/13 01:18:16 WARN DAGScheduler: Broadcasting large task binary with size 1755.2 KiB\n24/12/13 01:18:43 WARN DAGScheduler: Broadcasting large task binary with size 1756.3 KiB\n24/12/13 01:18:43 WARN DAGScheduler: Broadcasting large task binary with size 1755.2 KiB\n24/12/13 01:18:43 WARN DAGScheduler: Broadcasting large task binary with size 1756.3 KiB\n24/12/13 01:18:43 WARN DAGScheduler: Broadcasting large task binary with size 1755.2 KiB\n24/12/13 01:18:44 WARN DAGScheduler: Broadcasting large task binary with size 1756.3 KiB\n24/12/13 01:18:44 WARN DAGScheduler: Broadcasting large task binary with size 1755.2 KiB\n24/12/13 01:18:44 WARN DAGScheduler: Broadcasting large task binary with size 1756.3 KiB\n24/12/13 01:18:44 WARN DAGScheduler: Broadcasting large task binary with size 1755.2 KiB\n24/12/13 01:18:45 WARN DAGScheduler: Broadcasting large task binary with size 1756.3 KiB\n24/12/13 01:18:45 WARN DAGScheduler: Broadcasting large task binary with size 1755.2 KiB\n24/12/13 01:18:45 WARN DAGScheduler: Broadcasting large task binary with size 1756.3 KiB\n24/12/13 01:18:45 WARN DAGScheduler: Broadcasting large task binary with size 1755.2 KiB\n24/12/13 01:18:45 WARN DAGScheduler: Broadcasting large task binary with size 1756.3 KiB\n24/12/13 01:18:46 WARN DAGScheduler: Broadcasting large task binary with size 1755.2 KiB\n24/12/13 01:18:46 WARN DAGScheduler: Broadcasting large task binary with size 1756.3 KiB\n24/12/13 01:18:46 WARN DAGScheduler: Broadcasting large task binary with size 1755.2 KiB\n24/12/13 01:18:46 WARN DAGScheduler: Broadcasting large task binary with size 1756.3 KiB\n24/12/13 01:18:46 WARN DAGScheduler: Broadcasting large task binary with size 1755.2 KiB\n24/12/13 01:18:47 WARN DAGScheduler: Broadcasting large task binary with size 1756.3 KiB\n24/12/13 01:18:47 WARN DAGScheduler: Broadcasting large task binary with size 1755.2 KiB\n24/12/13 01:18:47 WARN DAGScheduler: Broadcasting large task binary with size 1756.3 KiB\n24/12/13 01:18:47 WARN DAGScheduler: Broadcasting large task binary with size 1755.2 KiB\n24/12/13 01:18:48 WARN DAGScheduler: Broadcasting large task binary with size 1756.3 KiB\n24/12/13 01:18:48 WARN DAGScheduler: Broadcasting large task binary with size 1755.2 KiB\n24/12/13 01:18:48 WARN DAGScheduler: Broadcasting large task binary with size 1756.3 KiB\n24/12/13 01:18:48 WARN DAGScheduler: Broadcasting large task binary with size 1755.2 KiB\n24/12/13 01:18:49 WARN DAGScheduler: Broadcasting large task binary with size 1756.3 KiB\n24/12/13 01:18:49 WARN DAGScheduler: Broadcasting large task binary with size 1755.2 KiB\n24/12/13 01:18:49 WARN DAGScheduler: Broadcasting large task binary with size 1756.3 KiB\n24/12/13 01:18:49 WARN DAGScheduler: Broadcasting large task binary with size 1755.2 KiB\n24/12/13 01:18:50 WARN DAGScheduler: Broadcasting large task binary with size 1756.3 KiB\n24/12/13 01:18:50 WARN DAGScheduler: Broadcasting large task binary with size 1755.2 KiB\n24/12/13 01:18:50 WARN DAGScheduler: Broadcasting large task binary with size 1756.3 KiB\n24/12/13 01:18:50 WARN DAGScheduler: Broadcasting large task binary with size 1755.2 KiB\n24/12/13 01:18:51 WARN DAGScheduler: Broadcasting large task binary with size 1756.3 KiB\n24/12/13 01:18:51 WARN DAGScheduler: Broadcasting large task binary with size 1755.2 KiB\n24/12/13 01:18:51 WARN DAGScheduler: Broadcasting large task binary with size 1756.3 KiB\n24/12/13 01:18:51 WARN DAGScheduler: Broadcasting large task binary with size 1755.2 KiB\n24/12/13 01:18:52 WARN DAGScheduler: Broadcasting large task binary with size 1756.3 KiB\n24/12/13 01:18:52 WARN DAGScheduler: Broadcasting large task binary with size 1755.2 KiB\n24/12/13 01:18:52 WARN DAGScheduler: Broadcasting large task binary with size 1756.3 KiB\n24/12/13 01:18:52 WARN DAGScheduler: Broadcasting large task binary with size 1755.2 KiB\n24/12/13 01:18:52 WARN DAGScheduler: Broadcasting large task binary with size 1756.3 KiB\n24/12/13 01:18:53 WARN DAGScheduler: Broadcasting large task binary with size 1755.2 KiB\n24/12/13 01:18:53 WARN DAGScheduler: Broadcasting large task binary with size 1756.3 KiB\n24/12/13 01:18:53 WARN DAGScheduler: Broadcasting large task binary with size 1755.2 KiB\n24/12/13 01:18:53 WARN DAGScheduler: Broadcasting large task binary with size 1756.3 KiB\n24/12/13 01:18:53 WARN DAGScheduler: Broadcasting large task binary with size 1755.2 KiB\n24/12/13 01:18:54 WARN DAGScheduler: Broadcasting large task binary with size 1756.3 KiB\n24/12/13 01:18:54 WARN DAGScheduler: Broadcasting large task binary with size 1755.2 KiB\n24/12/13 01:18:54 WARN DAGScheduler: Broadcasting large task binary with size 1756.3 KiB\n24/12/13 01:18:54 WARN DAGScheduler: Broadcasting large task binary with size 1755.2 KiB\n24/12/13 01:18:55 WARN DAGScheduler: Broadcasting large task binary with size 1756.3 KiB\n24/12/13 01:18:55 WARN DAGScheduler: Broadcasting large task binary with size 1755.2 KiB\n24/12/13 01:18:55 WARN DAGScheduler: Broadcasting large task binary with size 1756.3 KiB\n24/12/13 01:18:55 WARN DAGScheduler: Broadcasting large task binary with size 1755.2 KiB\n24/12/13 01:18:56 WARN DAGScheduler: Broadcasting large task binary with size 1756.3 KiB\n24/12/13 01:18:56 WARN DAGScheduler: Broadcasting large task binary with size 1755.2 KiB\n24/12/13 01:18:56 WARN DAGScheduler: Broadcasting large task binary with size 1756.3 KiB\n24/12/13 01:18:56 WARN DAGScheduler: Broadcasting large task binary with size 1755.2 KiB\n24/12/13 01:18:56 WARN DAGScheduler: Broadcasting large task binary with size 1756.3 KiB\n24/12/13 01:18:57 WARN DAGScheduler: Broadcasting large task binary with size 1755.2 KiB\n24/12/13 01:18:57 WARN DAGScheduler: Broadcasting large task binary with size 1756.3 KiB\n24/12/13 01:18:57 WARN DAGScheduler: Broadcasting large task binary with size 1755.2 KiB\n24/12/13 01:18:57 WARN DAGScheduler: Broadcasting large task binary with size 1756.3 KiB\n24/12/13 01:18:58 WARN DAGScheduler: Broadcasting large task binary with size 1755.2 KiB\n24/12/13 01:18:58 WARN DAGScheduler: Broadcasting large task binary with size 1756.3 KiB\n24/12/13 01:18:58 WARN DAGScheduler: Broadcasting large task binary with size 1755.2 KiB\n24/12/13 01:18:58 WARN DAGScheduler: Broadcasting large task binary with size 1756.3 KiB\n24/12/13 01:18:58 WARN DAGScheduler: Broadcasting large task binary with size 1755.2 KiB\n24/12/13 01:18:59 WARN DAGScheduler: Broadcasting large task binary with size 1756.3 KiB\n24/12/13 01:18:59 WARN DAGScheduler: Broadcasting large task binary with size 1755.2 KiB\n24/12/13 01:18:59 WARN DAGScheduler: Broadcasting large task binary with size 1756.3 KiB\n24/12/13 01:18:59 WARN DAGScheduler: Broadcasting large task binary with size 1818.5 KiB\n24/12/13 01:19:22 WARN DAGScheduler: Broadcasting large task binary with size 1819.6 KiB\n24/12/13 01:20:11 WARN DAGScheduler: Broadcasting large task binary with size 1819.0 KiB\n24/12/13 01:20:23 WARN DAGScheduler: Broadcasting large task binary with size 1820.1 KiB\n24/12/13 01:21:32 WARN DAGScheduler: Broadcasting large task binary with size 1756.0 KiB\n24/12/13 01:21:58 WARN DAGScheduler: Broadcasting large task binary with size 1757.2 KiB\n24/12/13 01:21:58 WARN DAGScheduler: Broadcasting large task binary with size 1756.5 KiB\n24/12/13 01:22:24 WARN DAGScheduler: Broadcasting large task binary with size 1757.6 KiB\n24/12/13 01:22:25 WARN DAGScheduler: Broadcasting large task binary with size 1756.5 KiB\n24/12/13 01:22:25 WARN DAGScheduler: Broadcasting large task binary with size 1757.6 KiB\n24/12/13 01:22:25 WARN DAGScheduler: Broadcasting large task binary with size 1756.5 KiB\n24/12/13 01:22:26 WARN DAGScheduler: Broadcasting large task binary with size 1757.6 KiB\n24/12/13 01:22:26 WARN DAGScheduler: Broadcasting large task binary with size 1756.5 KiB\n24/12/13 01:22:26 WARN DAGScheduler: Broadcasting large task binary with size 1757.6 KiB\n24/12/13 01:22:26 WARN DAGScheduler: Broadcasting large task binary with size 1756.5 KiB\n24/12/13 01:22:26 WARN DAGScheduler: Broadcasting large task binary with size 1757.6 KiB\n24/12/13 01:22:27 WARN DAGScheduler: Broadcasting large task binary with size 1756.5 KiB\n24/12/13 01:22:27 WARN DAGScheduler: Broadcasting large task binary with size 1757.6 KiB\n24/12/13 01:22:27 WARN DAGScheduler: Broadcasting large task binary with size 1756.5 KiB\n24/12/13 01:22:27 WARN DAGScheduler: Broadcasting large task binary with size 1757.6 KiB\n24/12/13 01:22:27 WARN DAGScheduler: Broadcasting large task binary with size 1756.5 KiB\n24/12/13 01:22:28 WARN DAGScheduler: Broadcasting large task binary with size 1757.6 KiB\n24/12/13 01:22:28 WARN DAGScheduler: Broadcasting large task binary with size 1756.5 KiB\n24/12/13 01:22:28 WARN DAGScheduler: Broadcasting large task binary with size 1757.6 KiB\n24/12/13 01:22:28 WARN DAGScheduler: Broadcasting large task binary with size 1756.5 KiB\n24/12/13 01:22:29 WARN DAGScheduler: Broadcasting large task binary with size 1757.6 KiB\n24/12/13 01:22:29 WARN DAGScheduler: Broadcasting large task binary with size 1756.5 KiB\n24/12/13 01:22:29 WARN DAGScheduler: Broadcasting large task binary with size 1757.6 KiB\n24/12/13 01:22:29 WARN DAGScheduler: Broadcasting large task binary with size 1756.5 KiB\n24/12/13 01:22:30 WARN DAGScheduler: Broadcasting large task binary with size 1757.6 KiB\n24/12/13 01:22:30 WARN DAGScheduler: Broadcasting large task binary with size 1756.5 KiB\n24/12/13 01:22:30 WARN DAGScheduler: Broadcasting large task binary with size 1757.6 KiB\n24/12/13 01:22:30 WARN DAGScheduler: Broadcasting large task binary with size 1756.5 KiB\n24/12/13 01:22:30 WARN DAGScheduler: Broadcasting large task binary with size 1757.6 KiB\n24/12/13 01:22:31 WARN DAGScheduler: Broadcasting large task binary with size 1756.5 KiB\n24/12/13 01:22:31 WARN DAGScheduler: Broadcasting large task binary with size 1757.6 KiB\n24/12/13 01:22:31 WARN DAGScheduler: Broadcasting large task binary with size 1756.5 KiB\n24/12/13 01:22:31 WARN DAGScheduler: Broadcasting large task binary with size 1757.6 KiB\n24/12/13 01:22:31 WARN DAGScheduler: Broadcasting large task binary with size 1756.5 KiB\n24/12/13 01:22:32 WARN DAGScheduler: Broadcasting large task binary with size 1757.6 KiB\n24/12/13 01:22:32 WARN DAGScheduler: Broadcasting large task binary with size 1756.5 KiB\n24/12/13 01:22:32 WARN DAGScheduler: Broadcasting large task binary with size 1757.6 KiB\n24/12/13 01:22:32 WARN DAGScheduler: Broadcasting large task binary with size 1756.5 KiB\n24/12/13 01:22:33 WARN DAGScheduler: Broadcasting large task binary with size 1757.6 KiB\n24/12/13 01:22:33 WARN DAGScheduler: Broadcasting large task binary with size 1756.5 KiB\n24/12/13 01:22:33 WARN DAGScheduler: Broadcasting large task binary with size 1757.6 KiB\n24/12/13 01:22:33 WARN DAGScheduler: Broadcasting large task binary with size 1756.5 KiB\n24/12/13 01:22:33 WARN DAGScheduler: Broadcasting large task binary with size 1757.6 KiB\n24/12/13 01:22:34 WARN DAGScheduler: Broadcasting large task binary with size 1756.5 KiB\n24/12/13 01:22:34 WARN DAGScheduler: Broadcasting large task binary with size 1757.6 KiB\n24/12/13 01:22:34 WARN DAGScheduler: Broadcasting large task binary with size 1756.5 KiB\n24/12/13 01:22:34 WARN DAGScheduler: Broadcasting large task binary with size 1757.6 KiB\n24/12/13 01:22:35 WARN DAGScheduler: Broadcasting large task binary with size 1756.5 KiB\n24/12/13 01:22:35 WARN DAGScheduler: Broadcasting large task binary with size 1757.6 KiB\n24/12/13 01:22:35 WARN DAGScheduler: Broadcasting large task binary with size 1756.5 KiB\n24/12/13 01:22:35 WARN DAGScheduler: Broadcasting large task binary with size 1757.6 KiB\n24/12/13 01:22:35 WARN DAGScheduler: Broadcasting large task binary with size 1756.5 KiB\n24/12/13 01:22:36 WARN DAGScheduler: Broadcasting large task binary with size 1757.6 KiB\n24/12/13 01:22:36 WARN DAGScheduler: Broadcasting large task binary with size 1756.5 KiB\n24/12/13 01:22:36 WARN DAGScheduler: Broadcasting large task binary with size 1757.6 KiB\n24/12/13 01:22:36 WARN DAGScheduler: Broadcasting large task binary with size 1756.5 KiB\n24/12/13 01:22:37 WARN DAGScheduler: Broadcasting large task binary with size 1757.6 KiB\n24/12/13 01:22:37 WARN DAGScheduler: Broadcasting large task binary with size 1756.5 KiB\n24/12/13 01:22:37 WARN DAGScheduler: Broadcasting large task binary with size 1757.6 KiB\n24/12/13 01:22:37 WARN DAGScheduler: Broadcasting large task binary with size 1756.5 KiB\n24/12/13 01:22:38 WARN DAGScheduler: Broadcasting large task binary with size 1757.6 KiB\n24/12/13 01:22:38 WARN DAGScheduler: Broadcasting large task binary with size 1756.5 KiB\n24/12/13 01:22:38 WARN DAGScheduler: Broadcasting large task binary with size 1757.6 KiB\n24/12/13 01:22:38 WARN DAGScheduler: Broadcasting large task binary with size 1756.5 KiB\n24/12/13 01:22:38 WARN DAGScheduler: Broadcasting large task binary with size 1757.6 KiB\n24/12/13 01:22:39 WARN DAGScheduler: Broadcasting large task binary with size 1756.5 KiB\n24/12/13 01:22:39 WARN DAGScheduler: Broadcasting large task binary with size 1757.6 KiB\n24/12/13 01:22:39 WARN DAGScheduler: Broadcasting large task binary with size 1756.5 KiB\n24/12/13 01:22:39 WARN DAGScheduler: Broadcasting large task binary with size 1757.6 KiB\n24/12/13 01:22:39 WARN DAGScheduler: Broadcasting large task binary with size 1756.5 KiB\n24/12/13 01:22:40 WARN DAGScheduler: Broadcasting large task binary with size 1757.6 KiB\n24/12/13 01:22:40 WARN DAGScheduler: Broadcasting large task binary with size 1756.5 KiB\n24/12/13 01:22:40 WARN DAGScheduler: Broadcasting large task binary with size 1757.6 KiB\n24/12/13 01:22:40 WARN DAGScheduler: Broadcasting large task binary with size 1756.5 KiB\n24/12/13 01:22:41 WARN DAGScheduler: Broadcasting large task binary with size 1757.6 KiB\n24/12/13 01:22:41 WARN DAGScheduler: Broadcasting large task binary with size 1756.5 KiB\n24/12/13 01:22:41 WARN DAGScheduler: Broadcasting large task binary with size 1757.6 KiB\n24/12/13 01:22:41 WARN DAGScheduler: Broadcasting large task binary with size 1819.8 KiB\n24/12/13 01:23:04 WARN DAGScheduler: Broadcasting large task binary with size 1820.9 KiB\n24/12/13 01:23:52 WARN DAGScheduler: Broadcasting large task binary with size 1820.4 KiB\n24/12/13 01:24:04 WARN DAGScheduler: Broadcasting large task binary with size 1821.5 KiB\n24/12/13 01:25:20 WARN DAGScheduler: Broadcasting large task binary with size 1797.3 KiB\n24/12/13 01:26:30 WARN DAGScheduler: Broadcasting large task binary with size 1798.5 KiB\n24/12/13 01:26:30 WARN DAGScheduler: Broadcasting large task binary with size 1797.8 KiB\n24/12/13 01:28:02 WARN DAGScheduler: Broadcasting large task binary with size 1799.0 KiB\n24/12/13 01:28:02 WARN DAGScheduler: Broadcasting large task binary with size 1797.8 KiB\n24/12/13 01:28:02 WARN DAGScheduler: Broadcasting large task binary with size 1799.0 KiB\n24/12/13 01:28:03 WARN DAGScheduler: Broadcasting large task binary with size 1797.8 KiB\n24/12/13 01:28:03 WARN DAGScheduler: Broadcasting large task binary with size 1799.0 KiB\n24/12/13 01:28:03 WARN DAGScheduler: Broadcasting large task binary with size 1797.8 KiB\n24/12/13 01:28:04 WARN DAGScheduler: Broadcasting large task binary with size 1799.0 KiB\n24/12/13 01:28:04 WARN DAGScheduler: Broadcasting large task binary with size 1797.8 KiB\n24/12/13 01:28:04 WARN DAGScheduler: Broadcasting large task binary with size 1799.0 KiB\n24/12/13 01:28:05 WARN DAGScheduler: Broadcasting large task binary with size 1797.8 KiB\n24/12/13 01:28:05 WARN DAGScheduler: Broadcasting large task binary with size 1799.0 KiB\n24/12/13 01:28:05 WARN DAGScheduler: Broadcasting large task binary with size 1797.8 KiB\n24/12/13 01:28:06 WARN DAGScheduler: Broadcasting large task binary with size 1799.0 KiB\n24/12/13 01:28:06 WARN DAGScheduler: Broadcasting large task binary with size 1797.8 KiB\n24/12/13 01:28:06 WARN DAGScheduler: Broadcasting large task binary with size 1799.0 KiB\n24/12/13 01:28:06 WARN DAGScheduler: Broadcasting large task binary with size 1797.8 KiB\n24/12/13 01:28:07 WARN DAGScheduler: Broadcasting large task binary with size 1799.0 KiB\n24/12/13 01:28:07 WARN DAGScheduler: Broadcasting large task binary with size 1797.8 KiB\n24/12/13 01:28:07 WARN DAGScheduler: Broadcasting large task binary with size 1799.0 KiB\n24/12/13 01:28:08 WARN DAGScheduler: Broadcasting large task binary with size 1797.8 KiB\n24/12/13 01:28:08 WARN DAGScheduler: Broadcasting large task binary with size 1799.0 KiB\n24/12/13 01:28:08 WARN DAGScheduler: Broadcasting large task binary with size 1797.8 KiB\n24/12/13 01:28:09 WARN DAGScheduler: Broadcasting large task binary with size 1799.0 KiB\n24/12/13 01:28:09 WARN DAGScheduler: Broadcasting large task binary with size 1797.8 KiB\n24/12/13 01:28:09 WARN DAGScheduler: Broadcasting large task binary with size 1799.0 KiB\n24/12/13 01:28:09 WARN DAGScheduler: Broadcasting large task binary with size 1797.8 KiB\n24/12/13 01:28:10 WARN DAGScheduler: Broadcasting large task binary with size 1799.0 KiB\n24/12/13 01:28:10 WARN DAGScheduler: Broadcasting large task binary with size 1797.8 KiB\n24/12/13 01:28:10 WARN DAGScheduler: Broadcasting large task binary with size 1799.0 KiB\n24/12/13 01:28:10 WARN DAGScheduler: Broadcasting large task binary with size 1797.8 KiB\n24/12/13 01:28:11 WARN DAGScheduler: Broadcasting large task binary with size 1799.0 KiB\n24/12/13 01:28:11 WARN DAGScheduler: Broadcasting large task binary with size 1797.8 KiB\n24/12/13 01:28:11 WARN DAGScheduler: Broadcasting large task binary with size 1799.0 KiB\n24/12/13 01:28:12 WARN DAGScheduler: Broadcasting large task binary with size 1797.8 KiB\n24/12/13 01:28:12 WARN DAGScheduler: Broadcasting large task binary with size 1799.0 KiB\n24/12/13 01:28:12 WARN DAGScheduler: Broadcasting large task binary with size 1797.8 KiB\n24/12/13 01:28:13 WARN DAGScheduler: Broadcasting large task binary with size 1799.0 KiB\n24/12/13 01:28:13 WARN DAGScheduler: Broadcasting large task binary with size 1797.8 KiB\n24/12/13 01:28:13 WARN DAGScheduler: Broadcasting large task binary with size 1799.0 KiB\n24/12/13 01:28:13 WARN DAGScheduler: Broadcasting large task binary with size 1797.8 KiB\n24/12/13 01:28:14 WARN DAGScheduler: Broadcasting large task binary with size 1799.0 KiB\n24/12/13 01:28:14 WARN DAGScheduler: Broadcasting large task binary with size 1797.8 KiB\n24/12/13 01:28:14 WARN DAGScheduler: Broadcasting large task binary with size 1799.0 KiB\n24/12/13 01:28:14 WARN DAGScheduler: Broadcasting large task binary with size 1797.8 KiB\n24/12/13 01:28:15 WARN DAGScheduler: Broadcasting large task binary with size 1799.0 KiB\n24/12/13 01:28:15 WARN DAGScheduler: Broadcasting large task binary with size 1797.8 KiB\n24/12/13 01:28:15 WARN DAGScheduler: Broadcasting large task binary with size 1799.0 KiB\n24/12/13 01:28:15 WARN DAGScheduler: Broadcasting large task binary with size 1797.8 KiB\n24/12/13 01:28:16 WARN DAGScheduler: Broadcasting large task binary with size 1799.0 KiB\n24/12/13 01:28:16 WARN DAGScheduler: Broadcasting large task binary with size 1797.8 KiB\n24/12/13 01:28:16 WARN DAGScheduler: Broadcasting large task binary with size 1799.0 KiB\n24/12/13 01:28:16 WARN DAGScheduler: Broadcasting large task binary with size 1797.8 KiB\n24/12/13 01:28:17 WARN DAGScheduler: Broadcasting large task binary with size 1799.0 KiB\n24/12/13 01:28:17 WARN DAGScheduler: Broadcasting large task binary with size 1797.8 KiB\n24/12/13 01:28:17 WARN DAGScheduler: Broadcasting large task binary with size 1799.0 KiB\n24/12/13 01:28:18 WARN DAGScheduler: Broadcasting large task binary with size 1797.8 KiB\n24/12/13 01:28:18 WARN DAGScheduler: Broadcasting large task binary with size 1799.0 KiB\n24/12/13 01:28:18 WARN DAGScheduler: Broadcasting large task binary with size 1797.8 KiB\n24/12/13 01:28:18 WARN DAGScheduler: Broadcasting large task binary with size 1799.0 KiB\n24/12/13 01:28:19 WARN DAGScheduler: Broadcasting large task binary with size 1797.8 KiB\n24/12/13 01:28:19 WARN DAGScheduler: Broadcasting large task binary with size 1799.0 KiB\n24/12/13 01:28:19 WARN DAGScheduler: Broadcasting large task binary with size 1797.8 KiB\n24/12/13 01:28:20 WARN DAGScheduler: Broadcasting large task binary with size 1799.0 KiB\n24/12/13 01:28:20 WARN DAGScheduler: Broadcasting large task binary with size 1797.8 KiB\n24/12/13 01:28:20 WARN DAGScheduler: Broadcasting large task binary with size 1799.0 KiB\n24/12/13 01:28:20 WARN DAGScheduler: Broadcasting large task binary with size 1797.8 KiB\n24/12/13 01:28:21 WARN DAGScheduler: Broadcasting large task binary with size 1799.0 KiB\n24/12/13 01:28:21 WARN DAGScheduler: Broadcasting large task binary with size 1797.8 KiB\n24/12/13 01:28:21 WARN DAGScheduler: Broadcasting large task binary with size 1799.0 KiB\n24/12/13 01:28:21 WARN DAGScheduler: Broadcasting large task binary with size 1797.8 KiB\n24/12/13 01:28:22 WARN DAGScheduler: Broadcasting large task binary with size 1799.0 KiB\n24/12/13 01:28:22 WARN DAGScheduler: Broadcasting large task binary with size 1797.8 KiB\n24/12/13 01:28:22 WARN DAGScheduler: Broadcasting large task binary with size 1799.0 KiB\n24/12/13 01:28:23 WARN DAGScheduler: Broadcasting large task binary with size 1863.8 KiB\n24/12/13 01:29:29 WARN DAGScheduler: Broadcasting large task binary with size 1864.9 KiB\n                                                                                \r"}, {"name": "stdout", "output_type": "stream", "text": "Average metric [126.28749819892796]\n"}, {"name": "stderr", "output_type": "stream", "text": "24/12/13 01:29:30 WARN DAGScheduler: Broadcasting large task binary with size 1858.2 KiB\n[Stage 446:>                                                        (0 + 1) / 1]\r"}, {"name": "stdout", "output_type": "stream", "text": "+-----------------+--------------------+---------------+------------------+----------------------------+-----------+--------------+---------+--------------+-------------------+--------------------------+-------------------+---------+------------------+\n|daysBetweenFlight|flightDate_OnWeekend|startingAirport|destinationAirport|travelduration_total_minutes|elapsedDays|isBasicEconomy|isNonStop|seatsRemaining|totalTravelDistance|segmentsArrivalAirportCode|segmentsCabinCode  |totalFare|prediction        |\n+-----------------+--------------------+---------------+------------------+----------------------------+-----------+--------------+---------+--------------+-------------------+--------------------------+-------------------+---------+------------------+\n|40               |1                   |ORD            |MIA               |186                         |0          |0             |1        |2             |1192.0             |MIA                       |coach              |338.61   |230.27730435815167|\n|40               |1                   |ORD            |MIA               |382                         |0          |0             |0        |7             |1824.0             |JFK||MIA                  |coach||coach       |347.61   |292.77696124976836|\n|40               |1                   |ORD            |MIA               |388                         |0          |0             |0        |9             |1824.0             |LGA||MIA                  |coach||coach       |328.6    |326.256957683872  |\n|40               |1                   |ORD            |MIA               |395                         |0          |0             |0        |9             |1196.0             |ATL||MIA                  |coach||coach       |328.6    |383.07486623728374|\n|40               |1                   |ORD            |MIA               |443                         |0          |0             |0        |9             |1824.0             |EWR||MIA                  |coach||coach       |357.6    |398.7453365452211 |\n|40               |1                   |ORD            |MIA               |450                         |0          |0             |0        |7             |1824.0             |JFK||MIA                  |coach||coach       |347.61   |297.4394933017781 |\n|40               |1                   |ORD            |MIA               |425                         |0          |0             |0        |9             |1824.0             |EWR||MIA                  |coach||coach       |357.6    |397.511136884395  |\n|40               |1                   |ORD            |OAK               |627                         |0          |0             |0        |3             |2285.0             |PDX||OAK                  |coach||coach       |547.2    |528.9182328468819 |\n|40               |1                   |ORD            |OAK               |653                         |0          |0             |0        |2             |1839.0             |SLC||OAK                  |coach||coach       |667.2    |483.79000192009295|\n|40               |1                   |ORD            |OAK               |720                         |0          |0             |0        |9             |2213.0             |MSP||LAX||OAK             |coach||coach||coach|725.1    |553.2086964010548 |\n|40               |1                   |ORD            |OAK               |720                         |0          |0             |0        |9             |2213.0             |MSP||LAX||OAK             |coach||coach||coach|725.1    |553.2086964010548 |\n|40               |1                   |ORD            |OAK               |902                         |1          |0             |0        |9             |2636.0             |AUS||SLC||OAK             |coach||coach||coach|767.7    |588.2269526974545 |\n|40               |1                   |ORD            |OAK               |1079                        |0          |0             |0        |7             |2612.0             |SLC||SEA||OAK             |coach||coach||coach|666.09   |606.3674415873011 |\n|40               |1                   |ORD            |OAK               |1109                        |0          |0             |0        |5             |2592.0             |DEN||SEA||OAK             |coach||coach||coach|636.09   |561.6504414542992 |\n|40               |1                   |ORD            |OAK               |442                         |0          |0             |0        |7             |2285.0             |PDX||OAK                  |coach||coach       |627.6    |531.4463676494759 |\n|40               |1                   |ORD            |OAK               |499                         |0          |0             |0        |7             |2395.0             |SEA||OAK                  |coach||coach       |627.6    |520.7745724308717 |\n|40               |1                   |ORD            |OAK               |506                         |0          |0             |0        |3             |2285.0             |PDX||OAK                  |coach||coach       |611.6    |520.6216684602174 |\n|40               |1                   |ORD            |OAK               |595                         |0          |0             |0        |9             |1919.0             |MSP||SLC||OAK             |coach||coach||coach|725.1    |662.3214288998561 |\n|40               |1                   |ORD            |PHL               |644                         |1          |0             |0        |7             |1142.0             |BOS||PHL                  |coach||coach       |312.19   |318.9229575260868 |\n|40               |1                   |ORD            |PHL               |690                         |1          |0             |0        |6             |1142.0             |BOS||PHL                  |coach||coach       |312.19   |318.2737821634824 |\n+-----------------+--------------------+---------------+------------------+----------------------------+-----------+--------------+---------+--------------+-------------------+--------------------------+-------------------+---------+------------------+\nonly showing top 20 rows\n\n"}, {"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "# Split the data into 70% training and 30% test sets  \ntrainingData, testData = sdf.randomSplit([0.7, 0.3], seed=42)\n\n# Create the pipeline   Indexer is stage 0 and Ridge Regression (ridge_reg)  is stage 5\nregression_pipe = Pipeline(stages=[indexer, encoder, distance_assembler, totalDistance_scaler, assembler, ridge_reg])\n\n# Create a grid to hold hyperparameters \ngrid = ParamGridBuilder()\n\n# Two ways to try .fitIntercept\nparams = ParamGridBuilder() \\\n.addGrid(ridge_reg.fitIntercept, [True, False]) \\\n.addGrid(ridge_reg.regParam, [0.001, 0.01, 0.1, 1, 10]) \\\n.addGrid(ridge_reg.elasticNetParam, [0, 0.25, 0.5, 0.75, 1]) \\\n.build()\n\n# Build the parameter grid\ngrid = grid.build()\n\nprint('Number of models to be tested: ', len(params))\n\n# Create the CrossValidator using the hyperparameter grid\ncv = CrossValidator(estimator=regression_pipe, \n                    estimatorParamMaps=grid, \n                    evaluator=evaluator, \n                    numFolds=3,seed=42)\n\n# Train the models\nall_models  = cv.fit(trainingData)\n\n# Show the average performance over the three folds for each grid combination\nprint(f\"Average metric {all_models.avgMetrics}\")\n\n# Get the best model from all of the models trained\nbestModel = all_models.bestModel\n\n# Use the model 'bestModel' to predict the test set\ntest_results = bestModel.transform(testData)\n\n# Show the predicted totalFare\ntest_results.select('daysBetweenFlight','flightDate_OnWeekend','startingAirport','destinationAirport', 'travelduration_total_minutes', 'elapsedDays', 'isBasicEconomy', 'isNonStop', 'seatsRemaining', 'totalTravelDistance', 'segmentsArrivalAirportCode', 'segmentsCabinCode', 'totalFare', 'prediction').show(truncate=False)"}, {"cell_type": "code", "execution_count": 16, "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "24/12/13 01:29:57 WARN DAGScheduler: Broadcasting large task binary with size 1864.6 KiB\n24/12/13 01:30:46 WARN DAGScheduler: Broadcasting large task binary with size 1865.7 KiB\n24/12/13 01:30:47 WARN DAGScheduler: Broadcasting large task binary with size 1864.6 KiB\n[Stage 449:================================================>      (16 + 2) / 18]\r"}, {"name": "stdout", "output_type": "stream", "text": "RMSE: 126.17129284242456  R-squared:0.5901663946609959\n[StringIndexerModel: uid=StringIndexer_f783778c07da, handleInvalid=keep, numInputCols=4, numOutputCols=4, OneHotEncoderModel: uid=OneHotEncoder_e79e52983a30, dropLast=false, handleInvalid=error, numInputCols=4, numOutputCols=4, VectorAssembler_a13b24a51454, MinMaxScalerModel: uid=MinMaxScaler_164b3517cfad, numFeatures=1, min=0.0, max=1.0, VectorAssembler_d20db549e9a8, LinearRegressionModel: uid=LinearRegression_564b952d632a, numFeatures=9977]\nbestModel intercept 213.7221382855052\nFeature Importance:\n  daysBetweenFlight: -2.336\n  flightDate_OnWeekend: -30.579\n  startingAirport: -17.970\n  destinationAirport: 21.467\n  travelduration_total_minutes: 2.673\n  elapsedDays: -11.462\n  isBasicEconomy: -21.451\n  isNonStop: 9.625\n  seatsRemaining: -15.032\n  totalTravelDistance: -36.966\n  segmentsArrivalAirportCode: 18.315\n  segmentsCabinCode: 15.875\n"}, {"name": "stderr", "output_type": "stream", "text": "24/12/13 01:31:33 WARN DAGScheduler: Broadcasting large task binary with size 1865.7 KiB\n                                                                                \r"}], "source": "# RMSE measures the differences between what the model predicted ('prediction') and the actual values ('totalFare').\nrmse = evaluator.evaluate(test_results, {evaluator.metricName:'rmse'})\n# R-Squared measures how much of the variability in the target variable (totalFare) can be explained by the model\nr2 =evaluator.evaluate(test_results,{evaluator.metricName:'r2'})\nprint(f\"RMSE: {rmse}  R-squared:{r2}\")\n\n# bestModel.coeff.\n# bestModel = all_models.bestModel\n# print(\"Coeeff \", bestModel.coeff)\n# bestModel = all_models.bestModel.stages(4)\n\nprint(bestModel.stages)\n\ncoefficients = bestModel.stages[5].coefficients\n# print(\"bestModel coefficients\", coefficients)\nintercept = bestModel.stages[5].intercept\nprint(\"bestModel intercept\", intercept)\n\n#Finding the most important features\nfeature_names = ['daysBetweenFlight','flightDate_OnWeekend','startingAirport','destinationAirport', 'travelduration_total_minutes', 'elapsedDays', 'isBasicEconomy', 'isNonStop', 'seatsRemaining', 'totalTravelDistance', 'segmentsArrivalAirportCode', 'segmentsCabinCode']\n\ncoef_map = dict(zip(feature_names, coefficients))\n\nprint(\"Feature Importance:\")\nfor feature, coef in coef_map.items():\n    print(\"  {}: {:.3f}\".format(feature, coef))\n"}, {"cell_type": "code", "execution_count": 18, "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "24/12/13 01:32:03 WARN DAGScheduler: Broadcasting large task binary with size 3.2 MiB\n                                                                                \r"}], "source": "transformed_sdf.write.parquet('gs://my-bigdata-project-rn/trusted/trusted_itineraries.parquet')"}, {"cell_type": "code", "execution_count": 23, "metadata": {"tags": []}, "outputs": [{"name": "stderr", "output_type": "stream", "text": "                                                                                \r"}], "source": "model_path =  'gs://my-bigdata-project-rn/models/plane_ridgelasso_regression_model'\nbestModel.write().overwrite().save(model_path)"}, {"cell_type": "code", "execution_count": 1, "metadata": {"tags": []}, "outputs": [{"ename": "NameError", "evalue": "name 'test_results' is not defined", "output_type": "error", "traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)", "Cell \u001b[0;32mIn[1], line 9\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# The Spark dataframe test_results holds the original 'totalFare' as well as the 'prediction'\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Select and convert to a Pandas dataframe\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mtest_results\u001b[49m\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtotalFare\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprediction\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mtoPandas()\n\u001b[1;32m     11\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Set the style for Seaborn plots\u001b[39;00m\n", "\u001b[0;31mNameError\u001b[0m: name 'test_results' is not defined"]}], "source": "# Visualize regression results\n\n# Plot totalFare against predicted totalFare (prediction)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# The Spark dataframe test_results holds the original 'totalFare' as well as the 'prediction'\n# Select and convert to a Pandas dataframe\ndf = test_results.select('totalFare','prediction').toPandas()\n\nplt.figure(figsize=(10,6))\n\n# Set the style for Seaborn plots\nsns.set_style(\"white\")\n \n# Create a relationship plot between totalFare and prediction\nsns.lmplot(x='totalFare', y='prediction', data=df)\n\nplt.savefig('RegressionPlot.png', dpi=600)\n"}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": []}, "outputs": [], "source": "# residuals = bestModel.stages[5].residuals\n# test_results.residuals\n\ndf = test_results.select('totalFare','prediction').toPandas()\ndf['residuals'] = df['totalFare'] - df['prediction']\n\nplt.figure(figsize=(10,6))\n\n# Set the style for Seaborn plots\nsns.set_style(\"white\")\n\n# Create a relationship plot between totalFare and prediction\nsns.regplot(x = 'prediction', y = 'residuals', data = df, scatter = True, color = 'red')\n\nplt.savefig('ResidualPlot.png', dpi=600)"}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": []}, "outputs": [], "source": "#Distribution of residuals\n\nplt.figure(figsize=(10,6))\n\nsns.histplot(df['residuals'], kde=True)\nplt.title(\"Distribution of Residuals\")\nplt.xlabel(\"Residuals\")\nplt.ylabel(\"Density\")\nplt.savefig('ResidualDist.png', dpi=600)\n\nplt.show()"}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": []}, "outputs": [], "source": "coeff_values = coefficients.toArray()"}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": []}, "outputs": [], "source": "#import pandas as pd\n#coef_df = pd.DataFrame({'Feature': feature_names, 'Coefficient': coeff_values})\nplt.barh(feature_names, coeff_values[0:12], color='skyblue')\nplt.xlabel(\"Coefficient Value\")\nplt.title(\"Coefficient Plot for Linear Regression\")\nplt.xticks(rotation=45)\nplt.axhline(y=0, color='black', linestyle='--')\nplt.show()"}, {"cell_type": "code", "execution_count": null, "metadata": {"tags": []}, "outputs": [], "source": "import scipy.stats as stats\n\n# Create Q-Q plot\nstats.probplot(df['residuals'], dist=\"norm\", plot=plt)\nplt.title('Normal Q-Q plot')\nplt.xlabel('Theoretical quantiles')\nplt.ylabel('Ordered Values')\nplt.grid(True)\n\nplt.savefig('QQPlotResiduals.png', dpi=600)\n\nplt.show()"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "PySpark", "language": "python", "name": "pyspark"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.11.8"}}, "nbformat": 4, "nbformat_minor": 4}